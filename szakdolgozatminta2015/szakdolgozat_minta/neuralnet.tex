%!TEX root = dolgozat.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Neural networks}\label{ch:INTRO}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Artificial neurons}\label{sec:INTRO:neurons}

\subsection{Sigmoid neuron}

The sigmoid neuron takes inputs with values between 0 and 1 and produces one output int the same interval.

[kep a nuronrol]

Weights are assigned to each input, representing their importance in the output of the neuron. Each neuron has a bias that is meant to correct small disorders in the behaviour of the network.

The output of a sigmoid neuron is calcualted with the \ref{eq:1} formula.

\begin{equation} \label{eq:1}
\sigma(\sum\limits_{i=1}^{n-1} w_{i}*x_{i} + b)
\end{equation}

\begin{equation} \label{eq:2}
\sigma(z) = \frac{1}{1+e^{-z}}
\end{equation}

A characteristic of the sigmoid neuron is that a small change in the weights produces a small change int the output. This can be a disandvantage as much as an advantage. It is an advantage because when the output is close to the desired outcome it can modify it won't step over it. It is a disadvantage becouse whene the output is terribly wrong, it takes a lot of time to correct is.

The function in the \ref{eq:1} formula is called an activation function.

\section{Architecture}\label{sec:INTRO:architecture}

I used a netwotk with 625 (25*25) input neurons representing the gray value of each pixel, and 46 (number of road sings categories) output neurons. I experimented with different numbers of hidden layers and various numbers of neurons in them.


\section{Stochastic gradient descent}\label{sec:INTRO:graddesc}

In order to teach the network, I introduced the quadratic cost function displayed in the \ref{eq:3} formula. n is the number of training inputs, y(x) is the output generated by the network for the x input and a is the desired output for the x input.

\begin{equation} \label{eq:3}
\ C = \frac{1}{2n}\sum\nolimits_{x} \|y(x)-a(x)\|^2
\end{equation}

My goal was to minimise the cost, beacause in the process the calculated output is getting closer to the desired outcome. 

\begin{equation} \label{eq:4}
\ w_{i} \rightarrow w_{i} - \eta\frac{\partial C}{\partial w_{i}} 
\end{equation}

\begin{equation} \label{eq:5}
\ b_{j} \rightarrow b_{j} - \eta\frac{\partial C}{\partial b_{j}} 
\end{equation}

\begin{equation} \label{eq:6}
\ \nabla C = (\frac{\partial C}{\partial w_{i}},\frac{\partial C}{\partial b_{j}})
\end{equation}

Gradient descent works by creating a mini-batch (a small number of randomly selected training inputs, $X_{i}$). The \ref{eq:7} equation shows that the actual cost is approximatly the same as the average of $\nabla C_{X_{i}}$ values.

\begin{equation} \label{eq:7}
\ \nabla C \approx \frac{1}{m} \sum\limits_{i=1}^m \nabla C_{X_{i}}
\end{equation}

\section{Backpropagation}\label{sec:INTRO:backprop}
